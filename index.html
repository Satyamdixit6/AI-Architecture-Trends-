<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Forging the Future: AI Architecture Trends</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #F7FAFC; /* Tailwind bg-gray-100 */
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 600px; /* Default max-width, can be overridden by Tailwind classes */
            margin-left: auto;
            margin-right: auto;
            height: 300px; /* Base height */
            max-height: 400px; /* Max height */
        }
        @media (min-width: 768px) { /* md breakpoint */
            .chart-container {
                height: 350px;
            }
        }
        .section-title {
            font-size: 2.25rem; /* Tailwind text-4xl */
            font-weight: 700; /* Tailwind font-bold */
            color: #2D3748; /* Tailwind text-gray-800 */
            margin-bottom: 1.5rem; /* Tailwind mb-6 */
            text-align: center;
        }
        .card {
            background-color: white;
            border-radius: 0.5rem; /* Tailwind rounded-lg */
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06); /* Tailwind shadow-md */
            padding: 1.5rem; /* Tailwind p-6 */
            margin-bottom: 1.5rem; /* Tailwind mb-6 */
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }
        .card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05); /* Tailwind shadow-xl */
        }
        .stat-number {
            font-size: 3rem; /* Tailwind text-5xl */
            font-weight: 700; /* Tailwind font-bold */
            color: #FF3D7F; /* Pink from palette */
        }
        .icon-placeholder {
            font-size: 2.5rem;
            line-height: 1;
            margin-bottom: 0.5rem;
        }
        /* Flowchart styles */
        .flow-box {
            border: 2px solid #00C6B5; /* Teal */
            padding: 0.75rem;
            border-radius: 0.375rem;
            text-align: center;
            background-color: #E6FFFA; /* Light Teal */
            min-height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .flow-arrow {
            font-size: 1.5rem;
            color: #7B61FF; /* Purple */
            margin: 0 0.5rem;
            display: flex;
            align-items: center;
        }
        .kpi-card {
            background-color: #4A5568; /* Tailwind bg-gray-700 */
            color: white;
            padding: 1rem;
            border-radius: 0.5rem;
            text-align: center;
        }
        .kpi-value {
            font-size: 2rem;
            font-weight: bold;
            color: #FFD700; /* Yellow */
        }
        .kpi-label {
            font-size: 0.875rem;
            color: #A0AEC0; /* Tailwind text-gray-400 */
        }

        /* Sticky Nav (Optional - uncomment if needed) */
        /*
        #sticky-nav {
            position: sticky;
            top: 0;
            background-color: rgba(255, 255, 255, 0.9);
            backdrop-filter: blur(10px);
            z-index: 50;
            padding: 0.5rem 0;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        #sticky-nav a {
            color: #7B61FF;
            transition: color 0.3s;
        }
        #sticky-nav a:hover {
            color: #FF3D7F;
        }
        */
    </style>
</head>
<body>
    <!-- 
        Infographic Narrative Plan:
        1. Hero: Title, Hook - AI's rapid evolution beyond established paradigms.
        2. The Shift: Visualizing the move from older models.
        3. Pioneering Architectures Overview: Key families from Table 1.
        4. Deep Dives: SSMs, KANs, AI Agents, MLA - showcasing unique aspects.
        5. Project Impact: Highlighting potential of new projects (Table 2).
        6. Strategic Considerations: Key takeaways for professionals.
        7. Conclusion: The dynamic future of AI.

        Color Palette Used: "Energetic & Playful"
        Pink: #FF3D7F
        Orange: #FF9E4F
        Yellow: #FFD700
        Teal: #00C6B5
        Purple: #7B61FF
        Primary Text: #2D3748 (Tailwind text-gray-800)
        Background: #F7FAFC (Tailwind bg-gray-100)

        Confirmation:
        - NO SVG graphics were used. All visuals are Chart.js (Canvas), HTML/CSS, or Unicode characters.
        - NO Mermaid JS was used. Diagrams are HTML/CSS.
    -->

    <header class="bg-gradient-to-r from-[#7B61FF] to-[#FF3D7F] text-white py-12 px-4 text-center">
        <h1 class="text-4xl md:text-5xl font-bold mb-4">Forging the Future: AI Architecture Trends</h1>
        <p class="text-lg md:text-xl max-w-3xl mx-auto">
            The AI landscape is evolving at an unprecedented pace, moving beyond established paradigms like Transformers, DiT, and standard MoE. This infographic explores the next wave of AI innovation.
        </p>
    </header>

    <!-- 
    <nav id="sticky-nav" class="hidden md:block">
        <div class="container mx-auto px-4">
            <ul class="flex justify-center space-x-6">
                <li><a href="#overview">Overview</a></li>
                <li><a href="#ssm">SSMs</a></li>
                <li><a href="#kan">KANs</a></li>
                <li><a href="#agents">AI Agents</a></li>
                <li><a href="#mla">MLA</a></li>
                <li><a href="#projects">Projects</a></li>
                <li><a href="#strategy">Strategy</a></li>
            </ul>
        </div>
    </nav>
    -->

    <main class="container mx-auto px-4 py-8">

        <section id="overview" class="py-8">
            <h2 class="section-title">The Shifting Landscape: Beyond Current Paradigms</h2>
            <p class="text-center text-lg text-gray-700 mb-8 max-w-2xl mx-auto">
                While Transformers, Diffusion Transformers (DiT), and standard Mixture of Experts (MoE) have been foundational, the quest for more powerful, efficient, and interpretable AI drives exploration into novel architectures. We're witnessing a move towards specialized, hybrid models and entirely new computational approaches.
            </p>
            <div class="grid grid-cols-1 md:grid-cols-3 gap-6 text-center">
                <div class="kpi-card">
                    <div class="kpi-value">9+</div>
                    <div class="kpi-label">Major Architectural Shifts Identified (Late 2023 - 2025)</div>
                </div>
                <div class="kpi-card">
                    <div class="kpi-value">PyTorch</div>
                    <div class="kpi-label">Dominant Framework for Cutting-Edge Research & Implementation</div>
                </div>
                <div class="kpi-card">
                    <div class="kpi-value">Hybrid</div>
                    <div class="kpi-label">Models Combining Strengths (e.g., SSM + Attention + MoE) are Key</div>
                </div>
            </div>
        </section>

        <section class="py-8">
            <h2 class="section-title">Pioneering Architectures at a Glance</h2>
            <p class="text-center text-lg text-gray-700 mb-10 max-w-2xl mx-auto">
                A diverse range of new AI architectures is emerging, each with unique strengths and "cool factors" that promise to redefine capabilities in various domains. These go beyond incremental improvements, offering distinct advantages over prior models.
            </p>
            <div class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-3 gap-6">
                <div class="card">
                    <div class="icon-placeholder" style="color: #FF9E4F;">🔗</div>
                    <h3 class="text-xl font-semibold mb-2 text-gray-800">Advanced State-Space Models (SSMs) & Hybrids</h3>
                    <p class="text-sm text-gray-600 mb-1"><strong class="text-gray-700">Novelty:</strong> Linear scaling, selective state, hybrid SSM-Transformer-MoE.</p>
                    <p class="text-sm text-gray-600"><strong class="text-gray-700">Impact:</strong> Ultra-long document understanding, efficient LLMs (e.g., Mamba, Jamba).</p>
                </div>
                <div class="card">
                    <div class="icon-placeholder" style="color: #FFD700;">🧠</div>
                    <h3 class="text-xl font-semibold mb-2 text-gray-800">Kolmogorov-Arnold Networks (KANs)</h3>
                    <p class="text-sm text-gray-600 mb-1"><strong class="text-gray-700">Novelty:</strong> Learnable activation functions on edges (splines).</p>
                    <p class="text-sm text-gray-600"><strong class="text-gray-700">Impact:</strong> High interpretability, scientific law discovery, XAI (e.g., pykan).</p>
                </div>
                <div class="card">
                    <div class="icon-placeholder" style="color: #00C6B5;">🧬</div>
                    <h3 class="text-xl font-semibold mb-2 text-gray-800">Generative Flow Networks (GFlowNets)</h3>
                    <p class="text-sm text-gray-600 mb-1"><strong class="text-gray-700">Novelty:</strong> Samples diverse, discrete objects proportional to a reward.</p>
                    <p class="text-sm text-gray-600"><strong class="text-gray-700">Impact:</strong> Drug/materials discovery, combinatorial optimization (e.g., torchgfn).</p>
                </div>
                <div class="card">
                    <div class="icon-placeholder" style="color: #7B61FF;">🤖</div>
                    <h3 class="text-xl font-semibold mb-2 text-gray-800">Advanced AI Agent Architectures</h3>
                    <p class="text-sm text-gray-600 mb-1"><strong class="text-gray-700">Novelty:</strong> LLMs with memory, planning, tool use for autonomous tasks.</p>
                    <p class="text-sm text-gray-600"><strong class="text-gray-700">Impact:</strong> Autonomous research, workflow automation (e.g., LangChain, AgentTorch).</p>
                </div>
                <div class="card">
                    <div class="icon-placeholder" style="color: #FF3D7F;">💡</div>
                    <h3 class="text-xl font-semibold mb-2 text-gray-800">Novel Attention/Memory Mechanisms</h3>
                    <p class="text-sm text-gray-600 mb-1"><strong class="text-gray-700">Novelty:</strong> KV cache compression (MLA), retrieval augmentation.</p>
                    <p class="text-sm text-gray-600"><strong class="text-gray-700">Impact:</strong> Hyper-efficient LLMs, longer context (e.g., DeepSeek-V2 MLA).</p>
                </div>
                 <div class="card">
                    <div class="icon-placeholder" style="color: #FF9E4F;">📈</div>
                    <h3 class="text-xl font-semibold mb-2 text-gray-800">Specialized Time Series Models</h3>
                    <p class="text-sm text-gray-600 mb-1"><strong class="text-gray-700">Novelty:</strong> MoE for time series, handling heterogeneity (e.g., Time-MoE).</p>
                    <p class="text-sm text-gray-600"><strong class="text-gray-700">Impact:</strong> Advanced forecasting, climate modeling.</p>
                </div>
            </div>
        </section>

        <section class="py-8">
            <h2 class="section-title">Spotlight on Key Innovations</h2>
            
            <div id="ssm" class="card md:col-span-2 lg:col-span-3 mb-12">
                <h3 class="text-2xl font-semibold mb-4 text-[#FF9E4F]">Deep Dive: Advanced State-Space Models (SSMs)</h3>
                <p class="text-gray-700 mb-6">
                    SSMs like Mamba and its hybrid successors (Jamba, Hymba) are revolutionizing long-sequence processing. Their linear or near-linear scaling with sequence length, compared to the quadratic complexity of Transformers, unlocks capabilities for analyzing extensive documents, genomic data, and long-form multimedia content. Jamba, for instance, supports context windows up to 256,000 tokens by hybridizing Mamba blocks with Transformer and MoE layers.
                </p>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                    <div>
                        <h4 class="text-lg font-semibold mb-2 text-gray-700">SSM Efficiency: Scaling with Sequence Length</h4>
                        <p class="text-sm text-gray-600 mb-2">Conceptual comparison of computational cost as sequence length increases. SSMs offer significant advantages for very long sequences.</p>
                        <div class="chart-container h-64 md:h-80 max-w-md">
                            <canvas id="ssmScalingChart"></canvas>
                        </div>
                    </div>
                    <div>
                        <h4 class="text-lg font-semibold mb-2 text-gray-700">Jamba: Hybrid Power (52B Parameters)</h4>
                        <p class="text-sm text-gray-600 mb-2">Jamba integrates MoE, activating only a fraction of its total parameters (12B active) for efficient inference.</p>
                        <div class="chart-container h-64 md:h-80 max-w-xs">
                            <canvas id="jambaParamsChart"></canvas>
                        </div>
                    </div>
                </div>
            </div>

            <div id="kan" class="card md:col-span-2 lg:col-span-3 mb-12">
                <h3 class="text-2xl font-semibold mb-4 text-[#FFD700]">Deep Dive: Kolmogorov-Arnold Networks (KANs)</h3>
                <p class="text-gray-700 mb-6">
                    KANs present a paradigm shift from traditional MLPs by placing learnable activation functions (splines) on network edges. This design, inspired by the Kolmogorov-Arnold representation theorem, offers enhanced interpretability and potential for higher accuracy with fewer parameters, especially in scientific discovery and symbolic regression tasks. KANs can reveal underlying mathematical formulas from data.
                </p>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-6 items-center">
                    <div>
                        <h4 class="text-lg font-semibold mb-2 text-gray-700">KAN Architecture: Edge-Based Activations</h4>
                        <p class="text-sm text-gray-600 mb-4">Unlike MLPs with node-based activations, KANs learn functions on connections, aiding interpretability.</p>
                        <div class="p-4 border border-dashed border-gray-300 rounded-lg">
                            <p class="text-center font-medium text-gray-700">MLP: Input → Node (Fixed Activation) → Output</p>
                            <div class="text-center text-2xl my-2">vs.</div>
                            <p class="text-center font-medium text-gray-700">KAN: Input → Edge (Learnable Spline Activation) → Node (Sum) → Output</p>
                            <p class="text-xs text-center text-gray-500 mt-2">(Simplified conceptual representation)</p>
                        </div>
                    </div>
                    <div>
                        <h4 class="text-lg font-semibold mb-2 text-gray-700">Key Benefit: Symbolic Discovery</h4>
                         <p class="text-sm text-gray-600 mb-2">KANs can often simplify learned splines into symbolic mathematical formulas (e.g., sin(x), x²), making them powerful for scientific insight.</p>
                        <div class="bg-yellow-50 p-4 rounded-lg text-center">
                            <span class="text-4xl">🔍</span>
                            <p class="mt-2 font-semibold text-yellow-700">Data to Equation</p>
                        </div>
                    </div>
                </div>
            </div>

            <div id="agents" class="card md:col-span-2 lg:col-span-3 mb-12">
                <h3 class="text-2xl font-semibold mb-4 text-[#7B61FF]">Deep Dive: Advanced AI Agent Architectures</h3>
                <p class="text-gray-700 mb-6">
                    AI agents, often powered by LLMs, represent a move towards autonomous systems. They incorporate memory, planning, and tool use (e.g., web search, code execution) to perceive environments, reason, and act to achieve complex goals. This enables applications like autonomous research assistants and automated workflow execution.
                </p>
                <div>
                    <h4 class="text-lg font-semibold mb-4 text-center text-gray-700">Core Cognitive Loop of an AI Agent</h4>
                    <div class="flex flex-col md:flex-row items-center justify-center space-y-4 md:space-y-0 md:space-x-2">
                        <div class="flow-box">Perception</div>
                        <div class="flow-arrow">➔</div>
                        <div class="flow-box">Memory & Knowledge</div>
                        <div class="flow-arrow">➔</div>
                        <div class="flow-box">Reasoning & Planning (LLM Core)</div>
                        <div class="flow-arrow">➔</div>
                        <div class="flow-box">Action Selection</div>
                        <div class="flow-arrow">➔</div>
                        <div class="flow-box">Tool Use / Execution</div>
                    </div>
                     <p class="text-xs text-center text-gray-500 mt-4">Agents interact with environments, learn, and adapt, moving AI from passive tools to active problem-solvers.</p>
                </div>
            </div>
            
            <div id="mla" class="card md:col-span-2 lg:col-span-3 mb-12">
                <h3 class="text-2xl font-semibold mb-4 text-[#FF3D7F]">Deep Dive: Novel Attention - Multi-Head Latent Attention (MLA)</h3>
                <p class="text-gray-700 mb-6">
                    Mechanisms like Multi-Head Latent Attention (MLA), pioneered by DeepSeek, address the efficiency bottleneck of Transformers. MLA significantly compresses the Key-Value (KV) cache by projecting keys and values into a lower-dimensional latent space, enabling longer effective context windows and boosting inference efficiency for LLMs.
                </p>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-6 items-center">
                    <div>
                        <h4 class="text-lg font-semibold mb-2 text-gray-700">KV Cache Compression with MLA</h4>
                        <p class="text-sm text-gray-600 mb-2">MLA can drastically reduce KV cache memory, vital for large models and long sequences. Reports suggest up to 10x increases in token memory capacity.</p>
                        <div class="chart-container h-64 md:h-80 max-w-md">
                            <canvas id="mlaKvCacheChart"></canvas>
                        </div>
                    </div>
                     <div>
                        <h4 class="text-lg font-semibold mb-2 text-gray-700">Impact of MLA</h4>
                        <ul class="list-disc list-inside text-gray-600 space-y-1">
                            <li>Enhanced LLM efficiency</li>
                            <li>Significantly longer effective context</li>
                            <li>Reduced memory footprint during inference</li>
                            <li>Improved throughput for generative tasks</li>
                        </ul>
                    </div>
                </div>
            </div>

        </section>

        <section id="projects" class="py-8 bg-gray-200 -mx-4 px-4">
            <h2 class="section-title">Project Impact: Building with Next-Gen AI</h2>
            <p class="text-center text-lg text-gray-700 mb-10 max-w-2xl mx-auto">
                Leveraging these advanced architectures in PyTorch projects can demonstrate cutting-edge skills and lead to impactful solutions in various domains, from scientific discovery to autonomous systems.
            </p>
            <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
                <div class="card">
                    <h4 class="text-lg font-semibold mb-2 text-gray-800">KAN-driven Scientific Discovery</h4>
                    <p class="text-sm text-gray-600 mb-2"><strong class="text-gray-700">Architecture:</strong> KANs</p>
                    <p class="text-sm text-gray-600 mb-2"><strong class="text-gray-700">Impact:</strong> Uncover symbolic equations from data, enhance interpretability in science.</p>
                    <p class="text-sm text-gray-600"><strong class="text-gray-700">Skills:</strong> Interpretable AI, Symbolic Regression, AI for Science.</p>
                </div>
                <div class="card">
                    <h4 class="text-lg font-semibold mb-2 text-gray-800">Autonomous Research Agent</h4>
                    <p class="text-sm text-gray-600 mb-2"><strong class="text-gray-700">Architecture:</strong> AI Agent + LLM + Tool Use</p>
                    <p class="text-sm text-gray-600 mb-2"><strong class="text-gray-700">Impact:</strong> Automate research tasks, summarize findings using external APIs.</p>
                    <p class="text-sm text-gray-600"><strong class="text-gray-700">Skills:</strong> Agent Design, LLM Integration, Prompt Engineering.</p>
                </div>
                <div class="card">
                    <h4 class="text-lg font-semibold mb-2 text-gray-800">Long-Context Multimodal Q&A</h4>
                    <p class="text-sm text-gray-600 mb-2"><strong class="text-gray-700">Architecture:</strong> Hybrid SSM-Transformer (Jamba-like)</p>
                    <p class="text-sm text-gray-600 mb-2"><strong class="text-gray-700">Impact:</strong> Q&A on long technical documents with text and diagrams.</p>
                    <p class="text-sm text-gray-600"><strong class="text-gray-700">Skills:</strong> Long-Context Modeling, Multimodal Processing, SSMs.</p>
                </div>
                <div class="card">
                    <h4 class="text-lg font-semibold mb-2 text-gray-800">Efficient Transformer with MLA</h4>
                    <p class="text-sm text-gray-600 mb-2"><strong class="text-gray-700">Architecture:</strong> Transformer + MLA</p>
                    <p class="text-sm text-gray-600 mb-2"><strong class="text-gray-700">Impact:</strong> Benchmark KV cache reduction and inference speed improvements.</p>
                    <p class="text-sm text-gray-600"><strong class="text-gray-700">Skills:</strong> Attention Optimization, Model Efficiency, Benchmarking.</p>
                </div>
                <div class="card">
                    <h4 class="text-lg font-semibold mb-2 text-gray-800">GFlowNet for Molecule Generation</h4>
                    <p class="text-sm text-gray-600 mb-2"><strong class="text-gray-700">Architecture:</strong> GFlowNets</p>
                    <p class="text-sm text-gray-600 mb-2"><strong class="text-gray-700">Impact:</strong> Generate novel molecular structures optimized for specific properties.</p>
                    <p class="text-sm text-gray-600"><strong class="text-gray-700">Skills:</strong> Generative Modeling for Science, RL Concepts.</p>
                </div>
            </div>
        </section>

        <section id="strategy" class="py-12">
            <h2 class="section-title">Strategic Considerations for AI Professionals</h2>
            <p class="text-center text-lg text-gray-700 mb-10 max-w-2xl mx-auto">
                Engaging with these advanced architectures requires aligning with career goals, managing complexity, and being mindful of ethical implications.
            </p>
            <div class="grid grid-cols-1 md:grid-cols-3 gap-8">
                <div class="card border-l-4 border-[#00C6B5]">
                    <h4 class="text-xl font-semibold mb-3 text-gray-800">Career Alignment</h4>
                    <ul class="list-disc list-inside text-sm text-gray-600 space-y-2">
                        <li><strong>Research Scientist:</strong> Focus on KANs, GFlowNets, Neurosymbolic AI.</li>
                        <li><strong>AI Engineer/Applied AI:</strong> AI Agents, MLA, Time-MoE applications.</li>
                        <li><strong>MLOps/Infrastructure:</strong> Model optimization (MLA), efficient deployment.</li>
                    </ul>
                </div>
                <div class="card border-l-4 border-[#FF9E4F]">
                    <h4 class="text-xl font-semibold mb-3 text-gray-800">Managing Complexity</h4>
                    <ul class="list-disc list-inside text-sm text-gray-600 space-y-2">
                        <li>Start with minimal viable projects.</li>
                        <li>Leverage pre-trained models and components where possible.</li>
                        <li>Be aware of computational costs and evolving tooling.</li>
                    </ul>
                </div>
                <div class="card border-l-4 border-[#FF3D7F]">
                    <h4 class="text-xl font-semibold mb-3 text-gray-800">Ethical Implications</h4>
                    <ul class="list-disc list-inside text-sm text-gray-600 space-y-2">
                        <li>Address bias in data and models (e.g., Jamba's noted Western bias).</li>
                        <li>Consider potential for misinformation from generative models.</li>
                        <li>Strive for explainability and trustworthiness (KANs aim here).</li>
                        <li>Ensure safety and alignment for autonomous agents.</li>
                    </ul>
                </div>
            </div>
        </section>

        <footer class="text-center py-10 border-t border-gray-300">
            <h3 class="text-2xl font-semibold text-gray-800 mb-3">The Dynamic Future of AI</h3>
            <p class="text-gray-600 max-w-2xl mx-auto">
                The AI landscape is in perpetual evolution. Engaging with these next-generation architectures is key to building more efficient, interpretable, and autonomous systems, shaping the future of technology and science. Continuous learning and adaptation are paramount for AI practitioners.
            </p>
            <p class="text-xs text-gray-500 mt-6">Infographic based on the report: "Forging the Future: Cutting-Edge PyTorch Projects with Next-Generation AI Architectures."</p>
        </footer>
    </main>

    <script>
        const pink = '#FF3D7F';
        const orange = '#FF9E4F';
        const yellow = '#FFD700';
        const teal = '#00C6B5';
        const purple = '#7B61FF';
        const gray = '#A0AEC0';

        function wrapLabels(labels, maxLength = 16) {
            return labels.map(label => {
                if (typeof label === 'string' && label.length > maxLength) {
                    const words = label.split(' ');
                    const lines = [];
                    let currentLine = '';
                    for (const word of words) {
                        if ((currentLine + word).length > maxLength && currentLine.length > 0) {
                            lines.push(currentLine.trim());
                            currentLine = word + ' ';
                        } else {
                            currentLine += word + ' ';
                        }
                    }
                    lines.push(currentLine.trim());
                    return lines;
                }
                return label;
            });
        }
        
        const tooltipTitleCallback = (tooltipItems) => {
            const item = tooltipItems[0];
            let label = item.chart.data.labels[item.dataIndex];
            if (Array.isArray(label)) {
                return label.join(' ');
            }
            return label;
        };

        // Chart 1: SSM Scaling Chart
        const ssmScalingCtx = document.getElementById('ssmScalingChart').getContext('2d');
        new Chart(ssmScalingCtx, {
            type: 'line',
            data: {
                labels: wrapLabels(['Short Seq', 'Medium Seq', 'Long Seq', 'Very Long Seq', 'Ultra Long Seq']),
                datasets: [{
                    label: 'Transformer (Quadratic)',
                    data: [1, 4, 16, 64, 256],
                    borderColor: pink,
                    backgroundColor: pink + '33', // opacity
                    tension: 0.1,
                    fill: false
                }, {
                    label: 'SSM (Near-Linear)',
                    data: [1, 2, 3, 4, 5],
                    borderColor: teal,
                    backgroundColor: teal + '33',
                    tension: 0.1,
                    fill: false
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    y: { 
                        beginAtZero: true,
                        title: { display: true, text: 'Relative Computational Cost' }
                    },
                    x: {
                        title: { display: true, text: 'Sequence Length' }
                    }
                },
                plugins: {
                    tooltip: { callbacks: { title: tooltipTitleCallback } },
                    title: { display: false }
                }
            }
        });

        // Chart 2: Jamba Parameters Chart
        const jambaParamsCtx = document.getElementById('jambaParamsChart').getContext('2d');
        new Chart(jambaParamsCtx, {
            type: 'doughnut',
            data: {
                labels: wrapLabels(['Active Parameters (12B)', 'Inactive Parameters (40B)']),
                datasets: [{
                    data: [12, 40],
                    backgroundColor: [purple, gray],
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                plugins: {
                    tooltip: { callbacks: { title: tooltipTitleCallback } },
                    title: { display: false },
                    legend: { position: 'bottom' }
                }
            }
        });
        
        // Chart 3: MLA KV Cache Chart
        const mlaKvCacheCtx = document.getElementById('mlaKvCacheChart').getContext('2d');
        new Chart(mlaKvCacheCtx, {
            type: 'bar',
            data: {
                labels: wrapLabels(['Standard Attention', 'MLA Enhanced Attention']),
                datasets: [{
                    label: 'Relative KV Cache Size',
                    data: [100, 15], // Conceptual values, DeepSeek reports up to 10x, so 100 vs 10-20
                    backgroundColor: [pink, teal],
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    y: { 
                        beginAtZero: true,
                        title: { display: true, text: 'Relative Cache Size Units' }
                    }
                },
                plugins: {
                    tooltip: { callbacks: { title: tooltipTitleCallback } },
                    title: { display: false },
                    legend: { display: false }
                }
            }
        });

        // Smooth scroll for internal links (optional, if nav is used)
        /*
        document.querySelectorAll('#sticky-nav a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                document.querySelector(this.getAttribute('href')).scrollIntoView({
                    behavior: 'smooth'
                });
            });
        });
        */

    </script>
</body>
</html>
